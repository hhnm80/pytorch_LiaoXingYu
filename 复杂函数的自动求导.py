# 上面我们展示了简单情况下的自动求导，都是对标量进行自动求导，可能你会有一个疑问，如何对一个向量或者矩阵自动求导了呢？感兴趣的同学可以自己先去尝试一下，下面我们会介绍对多维数组的自动求导机制。

import torch
from torch.autograd import Variable
# 这里面,在构建张量或者说构建数组的时候,有其形还要有其质,形就是矩阵的形状,质就是矩阵里面存储的数据,m的shape是(1,2),口诀"从外向里,从左往右"
m = Variable(torch.FloatTensor([[2, 3]]), requires_grad=True) # 构建一个 1 x 2 的矩阵

# 在构建0矩阵或者1矩阵的时候,我们需要了解的是Variable这个函数,关于这个函数的定义,我们可以百度之,就是把张量加入到一个节点里面,这种数据有grad属性，而torch数据没有该属性,torch的函数一般都与张量有关,而数组是numpy里面特有的,,,,,,,
# n不需要梯度么??????不需要梯度难道是常数么?????
n = Variable(torch.zeros(1, 2)) # 构建一个相同大小的 0 矩阵
print("m的值是:",m)
print("n的值是",n)

# 通过 m 中的值计算新的 n 中的值,这语句是什么意思呢?????是什么意思呢????以前没见过这种格式,这式子是什么意思呢????写得这么复杂,其实呢,这个是复合下标,只是python语言的语法太灵活了,所以才第一次见到这种写法,第一次见到,在c语言里面,二维数组,假设有一个二维数组,当然,我们现在用c语言表示二维数组,int a[3][4]={{1,2,3,4},{5,6,7,8},{9，10,11,12}};那么我们可以知道a[0][0]是什么东西呢????就是第一行第一列,同理,在这里是python语言的表达形式,
n[0, 0] = m[0, 0] ** 2
n[0, 1] = m[0, 1] ** 3
print(n)